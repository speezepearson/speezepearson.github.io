<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<!-- saved from url=(0114)https://web.archive.org/web/20160214232353/http://lesswrong.com/lw/del/real_world_solutions_to_prisoners_dilemmas/ -->
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<link href="./4_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./4_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include -->
<title>
Real World Solutions to Prisoners' Dilemmas - Less Wrong
</title>
<meta content="
rationality, optimal philanthropy, critical thinking, heuristics and biases, skeptic
" name="keywords"/>
<meta content="
Real World Solutions to Prisoners' Dilemmas - Less Wrong
" name="title"/>
<meta content="Why should there be real world solutions to Prisoners' Dilemmas? Because such dilemmas are a real-world problem.If I am assigned to work on a school project wit" name="description"/>
<!-- Start Visual Website Optimizer Asynchronous Code -->
<!-- End Visual Website Optimizer Asynchronous Code -->
<!--[if lte IE 8]>
<script src="/static/ie8below.js?v=(stdin)= 78e6f09c93f01df69ddef0ced465a511" type="text/javascript"></script>
<![endif]-->
<link href="./4_files/main.css" rel="stylesheet" type="text/css"/>
<link href="./4_files/Stylesheet" rel="stylesheet" type="text/css"/>
<link href="./4_files/lesswrong.css" rel="stylesheet" type="text/css"/>
<link href="./4_files/jquery.qtip.css" rel="stylesheet" type="text/css"/>
<!--[if lte IE 8]>
<link rel="stylesheet" type="text/css" href="/static/ie8below.css?v=(stdin)= 211a53181ad64730403441f5147876f4" />
<![endif]-->
<!--[if lte IE 7]>
<link rel="stylesheet" type="text/css" href="/static/ie7below.css?v=(stdin)= b43edf2e0f3764458e9118be01eab834" />
<![endif]-->
<!--[if IE 7]>
<link rel="stylesheet" type="text/css" href="/static/ie7.css?v=(stdin)= d41d8cd98f00b204e9800998ecf8427e" />
<![endif]-->
<!--[if lte IE 6]>
<link rel="stylesheet" type="text/css" href="/static/ie6.css?v=(stdin)= 8057c056f59a32b0740514cbe26ea377" />
<![endif]-->
<link href="https://web.archive.org/web/20160214232353im_/http://lesswrong.com/static/favicon.ico" rel="shortcut icon" type="image/x-icon"/>
<link href="https://web.archive.org/web/20160214232353/http://lesswrong.com/lw/del/real_world_solutions_to_prisoners_dilemmas/.rss" rel="alternate" title="RSS" type="application/rss+xml"/>
<link href="./4_files/default+pl.css" rel="stylesheet" type="text/css"/>
</head>
<body class="post" onclick="close_menus()">
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  min-width:800px !important;
}
.wb-autocomplete-suggestions {
    text-align: left; cursor: default; border: 1px solid #ccc; border-top: 0; background: #fff; box-shadow: -1px 1px 3px rgba(0,0,0,.1);
    position: absolute; display: none; z-index: 2147483647; max-height: 254px; overflow: hidden; overflow-y: auto; box-sizing: border-box;
}
.wb-autocomplete-suggestion { position: relative; padding: 0 .6em; line-height: 23px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: 1.02em; color: #333; }
.wb-autocomplete-suggestion b { font-weight: bold; }
.wb-autocomplete-suggestion.selected { background: #f0f0f0; }
</style>
<div class="wb-autocomplete-suggestions " style="left: 366px; top: 22px; width: 404px;"></div>
<!-- END WAYBACK TOOLBAR INSERT -->
<div id="wrapper">
<div class="lesswrong" id="header">
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/" id="logo">
<img alt="Less Wrong" id="header-img" src="./4_files/logo_trans.png"/>
</a>
<img alt="A community blog devoted to refining the art of human rationality" id="tagline" src="./4_files/tagline.png"/>
<a href="https://web.archive.org/web/20160214232353/http://www.fhi.ox.ac.uk/" id="fhi" target="_blank">Future of Humanity Institute</a>
<a href="https://web.archive.org/web/20160214232353/http://intelligence.org/" id="miri" target="_blank">Machine Intelligence Research Institute</a>
<a href="https://web.archive.org/web/20160214232353/http://rationality.org/" id="cfar" target="_blank">Center for Applied Rationality</a>
</div><!-- #header -->
<div class="clear" id="main">
<div class="clear " id="content">
<ul class="clear" id="nav">
<li class="active">
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/promoted/">Main</a>
<img alt="" class="dropdown" src="./4_files/nav-dropdown.gif"/>
<ul>
<li>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/promoted/">Posts</a>
</li>
<li>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/comments/">Comments</a>
</li>
</ul>
</li>
<li>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/r/discussion/new/">Discussion</a>
<img alt="" class="dropdown" src="./4_files/nav-dropdown.gif"/>
<ul>
<li>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/r/discussion/new/">Posts</a>
</li>
<li>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/r/discussion/comments/">Comments</a>
</li>
</ul>
</li>
</ul>
<div class="infobar"><div class="md"><p>Less Wrong is a community blog devoted to refining the art of human rationality. Please visit our <a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/about-less-wrong/" rel="nofollow">About</a> page for more information.</p></div></div>
<div class="sitetable" id="siteTable">
<div class="ajaxhook" id="ajaxHook">
</div>
<div class="post" id="thingrow_t3_del" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1 itemprop="name"><a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/lw/del/real_world_solutions_to_prisoners_dilemmas/">
Real World Solutions to Prisoners' Dilemmas
</a>
</h1>
<div class="meta clear">
<span class="votes">
<span class="votes " id="score_t3_del" oldtitle="83% positive">
31
</span>
</span>
<span class="author">
<span class="hide-text">Post author:</span>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/user/Yvain/" id="author_t3_del">Yvain</a>
</span>
<span class="date">03 July 2012 03:25AM</span>
</div><!-- .meta -->
<!--
<div>
<i><h0>Part 1 of 13 in the sequence &nbsp; <a href="http://wiki.lesswrong.com/wiki/Mysterious_Answers_to_Mysterious_Questions">Mysterious Answers to Mysterious Questions</a></h0></i>
<br/>
<br/>
</div>
-->
<div class="content clear" id="entry_t3_del">
<div class="md">
<div itemprop="description">
<div><p>Why should there be real world solutions to Prisoners' Dilemmas? Because such dilemmas are a real-world problem.<br/><br/>If I am assigned to work on a school project with a group, I can either cooperate (work hard on the project) or defect (slack off while reaping the rewards of everyone else's hard work). If everyone defects, the project doesn't get done and we all fail - a bad outcome for everyone. If I defect but you cooperate, then I get to spend all day on the beach and still get a good grade - the best outcome for me, the worst for you. And if we all cooperate, then it's long hours in the library but at least we pass the class - a “good enough” outcome, though not quite as good as me defecting against everyone else's cooperation. This exactly mirrors the Prisoner's Dilemma.<br/><br/>Diplomacy - both the concept and the board game - involves Prisoners' Dilemmas. Suppose Ribbentrop of Germany and Molotov of Russia agree to a peace treaty that demilitarizes their mutual border. If both cooperate, they can move their forces to other theaters, and have moderate success there - a good enough outcome. If Russia cooperates but Germany defects, it can launch a surprise attack on an undefended Russian border and enjoy spectacular success there (for a while, at least!) - the best outcome for Germany and the worst for Russia. But if both defect, then neither has any advantage at the German-Russian border, and they lose the use of those troops in other theaters as well - a bad outcome for both. Again, the Prisoner's Dilemma.<br/><br/>Civilization - again, both the concept and the game - involves Prisoners' Dilemmas. If everyone follows the rules and creates a stable society (cooperates), we all do pretty well. If everyone else works hard and I turn barbarian and pillage you (defect), then I get all of your stuff without having to work for it and you get nothing - the best solution for me, the worst for you. If everyone becomes a barbarian, there's nothing to steal and we all lose out. Prisoner's Dilemma.<br/><br/>If everyone who worries about global warming cooperates in cutting emissions, climate change is averted and everyone is moderately happy. If everyone else cooperates in cutting emissions, but one country defects, climate change is still mostly averted, and the defector is at a significant economic advantage. If everyone defects and keeps polluting, the climate changes and everyone loses out. Again a Prisoner's Dilemma,<br/><br/>Prisoners' Dilemmas even come up in nature. In baboon tribes, when a female is in “heat”, males often compete for the chance to woo her. The most successful males are those who can get a friend to help fight off the other monkeys, and who then helps that friend find his own monkey loving. But these monkeys are tempted to take their friend's female as well. Two males who cooperate each seduce one female. If one cooperates and the other defects, he has a good chance at both females. But if the two can't cooperate at all, then they will be beaten off by other monkey alliances and won't get to have sex with anyone. Still a Prisoner's Dilemma!</p>
<p>So one might expect the real world to have produced some practical solutions to Prisoners' Dilemmas.<br/><br/>One of the best known such systems is called “society”. You may have heard of it. It boasts a series of norms, laws, and authority figures who will punish you when those norms and laws are broken.<br/><br/>Imagine that the two criminals in the original example were part of a criminal society - let's say the Mafia. The Godfather makes Alice and Bob an offer they can't refuse: turn against one another, and they will end up “sleeping with the fishes” (this concludes my knowledge of the Mafia). Now the incentives are changed: defecting against a cooperator doesn't mean walking free, it means getting murdered.</p>
<p><img alt="" src="./4_files/mafiatree.png" width="701"/><br/><br/><img alt="" src="./4_files/mafiatree2.png" width="701"/><br/><br/>Both prisoners cooperate, and amazingly the threat of murder ends up making them both better off (this is also the gist of some of the strongest arguments against libertarianism: in Prisoner's Dilemmas, threatening force against rational agents can increase the utility of all of them!)<br/><br/>Even when there is no godfather, society binds people by concern about their “reputation”. If Bob got a reputation as a snitch, he might never be able to work as a criminal again. If a student gets a reputation for slacking off on projects, she might get ostracized on the playground. If a country gets a reputation for backstabbing, others might refuse to make treaties with them. If a person gets a reputation as a bandit, she might incur the hostility of those around her. If a country gets a reputation for not doing enough to fight global warming, it might...well, no one ever said it was a perfect system.<br/><br/>Aside from humans in society, evolution is also strongly motivated to develop a solution to the Prisoner's Dilemma. The Dilemma troubles not only lovestruck baboons, but <a href="https://web.archive.org/web/20160214232353/http://brembs.net/ipd/ants.html#HD_NM_17">ants</a>, <a href="https://web.archive.org/web/20160214232353/http://brembs.net/ipd/inspect.html#HD_NM_18">minnows</a>, <a href="https://web.archive.org/web/20160214232353/http://brembs.net/ipd/vampire.html#HD_NM_20">bats</a>, and even <a href="https://web.archive.org/web/20160214232353/http://www.nature.com/nature/journal/v398/n6726/abs/398441a0.html">viruses</a>. Here the payoff is denominated not in years of jail time, nor in dollars, but in reproductive fitness and number of potential offspring - so evolution will certainly take note.<br/><br/>Most people, when they hear the rational arguments in favor of defecting every single time on the iterated 100-crime Prisoner's Dilemma, will feel some kind of emotional resistance. Thoughts like “Well, maybe I'll try cooperating anyway a few times, see if it works”, or “If I promised to cooperate with my opponent, then it would be dishonorable for me to defect on the last turn, even if it helps me out., or even “Bob is my friend! Think of all the good times we've had together, robbing banks and running straight into waiting police cordons. I could never betray him!”<br/><br/>And if two people with these sorts of emotional hangups play the Prisoner's Dilemma together, they'll end up cooperating on all hundred crimes, getting out of jail in a mere century and leaving rational utility maximizers to sit back and wonder how they did it.<br/><br/>Here's how: imagine you are a supervillain designing a robotic criminal (who's that go-to supervillain Kaj always uses for situations like this? Dr. Zany? Okay, let's say you're him). You expect to build several copies of this robot to work as a team, and expect they might end up playing the Prisoner's Dilemma against each other. You want them out of jail as fast as possible so they can get back to furthering your nefarious plots. So rather than have them bumble through the whole rational utility maximizing thing, you just insert an extra line of code: “in a Prisoner's Dilemma, always cooperate with other robots”. Problem solved.<br/><br/>Evolution followed the same strategy (no it didn't; this is a massive oversimplification). The emotions we feel around friendship, trust, altruism, and betrayal are partly a built-in hack to succeed in cooperating on Prisoner's Dilemmas where a rational utility-maximizer would defect a hundred times and fail miserably. The evolutionarily dominant strategy is commonly called “<a href="https://web.archive.org/web/20160214232353/http://en.wikipedia.org/wiki/Tit_for_tat">Tit-for-tat</a>” - basically, cooperate if and only if your opponent did so last time.<br/><br/>This so-called "superrationality” appears even more clearly in the Ultimatum Game. Two players are given $100 to distribute among themselves in the following way: the first player proposes a distribution (for example, “Fifty for me, fifty for you”) and then the second player either accepts or rejects the distribution. If the second player accepts, the players get the money in that particular ratio. If the second player refuses, no one gets any money at all.<br/><br/>The first player's reasoning goes like this: “If I propose $99 for myself and $1 for my opponent, that means I get a lot of money and my opponent still has to accept. After all, she prefers $1 to $0, which is what she'll get if she refuses.<br/><br/>In the Prisoner's Dilemma, when players were able to communicate beforehand they could settle upon a winning strategy of precommiting to reciprocate: to take an action beneficial to their opponent if and only if their opponent took an action beneficial to them. Here, the second player should consider the same strategy: precommit to an ultimatum (hence the name) that unless Player 1 distributes the money 50-50, she will reject the offer.<br/><br/>But as in the Prisoner's Dilemma, this fails when you have no reason to expect your opponent to follow through on her precommitment. Imagine you're Player 2, playing a single Ultimatum Game against an opponent you never expect to meet again. You dutifully promise Player 1 that you will reject any offer less than 50-50. Player 1 offers 80-20 anyway. You reason “Well, my ultimatum failed. If I stick to it anyway, I walk away with nothing. I might as well admit it was a good try, give in, and take the $20. After all, rejecting the offer won't magically bring my chance at $50 back, and there aren't any other dealings with this Player 1 guy for it to influence.”<br/><br/>This is seemingly a rational way to think, but if Player 1 knows you're going to think that way, she offers 99-1, same as before, no matter how sincere your ultimatum sounds.<br/><br/>Notice all the similarities to the Prisoner's Dilemma: playing as a "rational economic agent" gets you a bad result, it looks like you can escape that bad result by making precommitments, but since the other player can't trust your precommitments, you're right back where you started<br/><br/>If evolutionary solutions to the Prisoners' Dilemma look like trust or friendship or altruism, solutions to the Ultimatum Game involve different emotions entirely. The Sultan presumably does not want you to elope with his daughter. He makes an ultimatum: “Touch my daughter, and I will kill you.” You elope with her anyway, and when his guards drag you back to his palace, you argue: “Killing me isn't going to reverse what happened. Your ultimatum has failed. All you can do now by beheading me is get blood all over your beautiful palace carpet, which hurts you as well as me - the equivalent of pointlessly passing up the last dollar in an Ultimatum Game where you've just been offered a 99-1 split.”<br/><br/>The Sultan might counter with an argument from social institutions: “If I let you go, I will look dishonorable. I will gain a reputation as someone people can mess with without any consequences. My choice isn't between bloody carpet and clean carpet, it's between bloody carpet and people respecting my orders, or clean carpet and people continuing to defy me.”<br/><br/>But he's much more likely to just shout an incoherent stream of dreadful Arabic curse words. Because just as friendship is the evolutionary solution to a Prisoner's Dilemma, so anger is the evolutionary solution to an Ultimatum Game. As various gurus and psychologists have observed, anger makes us irrational. But this is the good kind of irrationality; it's the kind of irrationality that makes us pass up a 99-1 split even though the decision costs us a dollar.<br/><br/>And if we know that humans are the kind of life-form that tends to experience anger, then if we're playing an Ultimatum Game against a human, and that human precommits to rejecting any offer less than 50-50, we're much more likely to believe her than if we were playing against a rational utility-maximizing agent - and so much more likely to give the human a fair offer.<br/><br/>It is distasteful and a little bit contradictory to the spirit of rationality to believe it should lose out so badly to simple emotion, and the problem might be correctable. Here we risk crossing the poorly charted border between game theory and decision theory and reaching ideas like <a href="https://web.archive.org/web/20160214232353/http://wiki.lesswrong.com/wiki/Timeless_decision_theory">timeless decision theory</a>: that one should act as if one's choices determined the output of the algorithm one instantiates (or more simply, you should assume everyone like you will make the same choice you do, and take that into account when choosing.)<br/><br/>More practically, however, most real-world solutions to Prisoner's Dilemmas and Ultimatum Games still hinge on one of three things: threats of reciprocation when the length of the game is unknown, social institutions and reputation systems that make defection less attractive, and emotions ranging from cooperation to anger that are hard-wired into us by evolution. In the next post, we'll look at how these play out in practice.</p></div>
</div>
</div>
</div><!-- .content -->
<div class="articlenavigation">
<h4><a class="dsphead" href="javascript:void(0)" id="articlenavstate" onclick="toggle_article_navigation('del')">Article Navigation</a></h4>
<div class="dspcont" id="article_nav_controls" style="display: none;">
<span class="loading"><img alt="" src="./4_files/ajax-loader.gif"/>
Loading…</span>
</div>
</div><!-- .articlenavigation -->
<div class="tools clear">
<div class="vote" id="arrows_t3_del">
<a class="up" id="up_t3_del" oldtitle="Vote up" onclick="showcover(true, 'vote_t3_del')">Vote up</a>
<a class="down" id="down_t3_del" oldtitle="Vote down" onclick="showcover(true, 'vote_t3_del')">Vote down</a>
<span class="loading" id="votespinner_t3_del"><img alt="" src="./4_files/ajax-loader.gif"/></span>
</div>
<a class="comment" href="https://web.archive.org/web/20160214232353/http://lesswrong.com/lw/del/real_world_solutions_to_prisoners_dilemmas/#comments">Comments (87)</a>
<div class="boxright clear">
<ul class="clear">
</ul>
<div class="tags">
<span>Tags:</span>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/tag/game_theory/">game_theory</a>
<span class="separator"> </span>
</div>
</div>
<span class="error" id="status_t3_del" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
</div>

</div>
<div id="sidebar">
<ul class="clear" id="rightnav">
<li>
<a href="https://web.archive.org/web/20160214232353/http://wiki.lesswrong.com/">wiki</a>
</li>
<li>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/sequences/">Sequences</a>
</li>
<li>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/about/">About</a>
</li>
</ul>
<div class="spacer">
<div class="sidebox" id="side-search">
<form action="https://web.archive.org/web/20160214232353/http://lesswrong.com/search/results" id="cse-search-box" onsubmit="return true;">
<div>
<input name="cx" type="hidden" value="015839050583929870010:-802ptn4igi"/>
<input name="cof" type="hidden" value="FORID:11"/>
<input name="ie" type="hidden" value="UTF-8"/>
<input class="text" id="search-query" name="q" size="31" style='background: url("https://www.google.com/cse/static/en/google_custom_search_watermark.gif") left center no-repeat rgb(255, 255, 255);' type="text"/>
<input class="submit" name="sa" type="submit" value="Search"/>
</div>
<input name="siteurl" type="hidden" value="web.archive.org/web/20160214232353/http://lesswrong.com/lw/del/real_world_solutions_to_prisoners_dilemmas/"/><input name="ref" type="hidden" value="web.archive.org/web/20160301000000*/http://lesswrong.com/lw/del/real_world_solutions_to_prisoners_dilemmas/"/><input name="ss" type="hidden" value=""/></form>
<form style="display:none">
<input id="cse-search-transformed" type="hidden" value="0"/>
</form>
</div><!-- #side-search -->
</div>
<div class="spacer">
<div class="sidebox" id="side-login">
<form action="https://web.archive.org/web/20160214232353/http://lesswrong.com/post/login" class="login-form-side" method="post" onsubmit="return chklogin(this);">
<div class="row">
<label for="username">
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/" onclick="return showcover(false);">Register</a>
/ Login</label>
<input name="op" type="hidden" value="login-main"/>
<input id="username" maxlength="20" name="user_login" tabindex="1" type="text"/>
</div>
<div class="row">
<label for="password">Password</label>
<input id="password" maxlength="20" name="passwd_login" tabindex="2" type="password"/>
</div>
<div class="row">
<div id="remember-me">
<label for="rem-login-main">Remember me</label>
<input id="rem-login-main" name="rem" tabindex="3" type="checkbox"/>
</div>
</div>
<div>
<div class="error" id="WRONG_PASSWORD_login-main">
</div>
<div class="error" id="status_login-main"></div>
</div>
<div class="row">
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/password" id="recover">Recover password</a>
<button class="btn" tabindex="4" type="submit">Login</button>
</div>
</form>
</div>
</div>
<div class="spacer">
<div class="sidebox" id="side-feed">
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/lw/del/real_world_solutions_to_prisoners_dilemmas/.rss">
<img alt="Feed icon" src="./4_files/feed.png"/>
Subscribe to RSS Feed
</a>
</div>
</div>
<div class="spacer">
<div class="sidebox" id="side-meetups">
<link href="./4_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./4_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2 class="meetup-title">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/meetups">Nearest Meetups</a>
</h2>
<ul>
<li>
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/meetups/1f8">
San Antonio, TX: <span class="date">12 July 2015 01:30PM</span>
</a>
</li>
<li>
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/meetups/18x">
Durham, NC (RTLW) Discussion Meetup: <span class="date">02 July 2026 07:00PM</span>
</a>
</li>
</ul></div>
</div>
<div class="spacer">
<div class="sidebox" id="side-studyroom">
<h2 class="studyroom-title">
<a href="https://web.archive.org/web/20160214232353/https://complice.co/room/lesswrong">Virtual Study Room</a>
</h2>
Co-work with other rationalists online.<br/>
<ul>
<li>
<a href="https://web.archive.org/web/20160214232353/https://complice.co/room/lesswrong"><strong>Less Wrong Study Hall</strong>
</a>
</li>
</ul>
</div>
</div>
<div class="spacer">
<div class="sidebox" id="side-comments">
<link href="./4_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./4_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2>
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/comments">Recent Comments</a>
</h2>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/lx/argument_screens_off_authority/cjxg?context=1#cjxg">&gt;We observe that politicians are happy to cut taxes (for people who can benefit them) if they personally get paid as much or more than before. Why would it be otherwise? Having the ability to take and redistribute someone else's money provides a concentrated benefit to the one doing the taking and redistributing. Cutting taxes produces a much more diffuse benefit. Concentrated benefits lead to Machiavellian behavior much more than diffuse benefits. It is possible, of course, to have an anti-taxes lobbying group which provides a concentrated benefit, but the overall balance between concentrated and diffuse benefits is on the side of the higher taxes.
&gt;(And any long-term interest, eg power for their family, should take the state of their civilization into account.)
That would be a diffuse cost. The politician may care about the portion of the diffuse effectthat affects his family, but that's only a small portion of the total. If the politician makes policy based on which costs help him and his family and which ones hurt him and his family, the concentrated ones will win. The ones that affect all civilization, a small portion of which he actually cares about because it goes to his family, will lose.</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Jiro">
<strong>Jiro</strong></a>
on
Argument Screens Off Authority |
<span id="score_t1_cjxg">0 points</span>
</span>
</div>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/1jm/getting_over_dust_theory/cjx9?context=1#cjx9">&gt; don't think there's a meaningful difference between "the real world" and a perfect simulation of it (at least seen "from the inside") -
What's the meaning of meaningful? Do you mean that you literally cannot understand the opposite of simulationism? Or are using "meaningful" to mean "empirically confirmable"? The empirical indetectability of a simulation follows from simulations premises, right enough....but it cannot be used to argue for them.</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/TheAncientGeek">
<strong>TheAncientGeek</strong></a>
on
Getting Over Dust Theory |
<span id="score_t1_cjx9">0 points</span>
</span>
</div>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/1sm/akrasia_tactics_review/cjwp?context=1#cjwp">**Missing techniques:**
* [caching your identity](http://lesswrong.com/lw/4e/cached_selves/)
* [goal factoring](http://lesswrong.com/lw/8gv/the_curse_of_identity/)
* [solutions for the human memory problem sets in the comments](http://lesswrong.com/lw/iwq/human_memory_problem_set/)
* [insight into procrastination, which is spread over several posts including this link](http://lesswrong.com/lw/3kv/working_hurts_less_than_procrastinating_we_fear/)
* [Preempting excuses](http://lesswrong.com/lw/24o/eight_short_studies_on_excuses/)
**both missing reviews and missing a write up on Lesswrong**
* [SOBER technique](http://smartrecoveryaustralia.com.au/s-o-b-e-r/)
**Techniques I've tried and will put up a review for soon hopefully:**
* [check cosequentialism](http://lesswrong.com/lw/b4f/sotw_check_consequentialism/)</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Clarity">
<strong>Clarity</strong></a>
on
Akrasia Tactics Review |
<span id="score_t1_cjwp">1 point</span>
</span>
</div>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/mgi/rational_vs_reasonable/cjwm?context=1#cjwm">I'd like to become a more reasonable person. How do I change my mindset to make such behaviors more common?</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/27chaos">
<strong>27chaos</strong></a>
on
Rational vs Reasonable |
<span id="score_t1_cjwm">0 points</span>
</span>
</div>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/lx/argument_screens_off_authority/cjwa?context=1#cjwa">No, you did not. A Machiavellan politician wants to stay in power, that is, to be elected. You're asserting a group interest that does not exist. We observe that politicians are happy to cut taxes (for people who can benefit them) if they personally get paid as much or more than before. Why would it be otherwise? (And any long-term interest, eg power for their family, should take the state of their civilization into account.)</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/hairyfigment">
<strong>hairyfigment</strong></a>
on
Argument Screens Off Authority |
<span id="score_t1_cjwa">0 points</span>
</span>
</div></div>
</div>
<div class="spacer">
<div class="sidebox" id="side-posts">
<link href="./4_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./4_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2>
<a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/recentposts">Recent Posts</a>
</h2>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mgi/rational_vs_reasonable/">
Rational vs Reasonable
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/abramdemski">
abramdemski</a> |
6v (1c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mgh/new_lw_meetup_kyiv/">
New LW Meetup: Kyiv
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/FrankAdamek">
FrankAdamek</a> |
1v (0c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mft/european_community_weekend_2015_followup/">
European Community Weekend 2015 - Followup
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/Lachouette">
Lachouette</a> |
16v (7c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/me1/the_unfriendly_superintelligence_next_door/">
The Unfriendly Superintelligence next door
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/jacob_cannell">
jacob_cannell</a> |
40v (63c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mf7/harpers_fishing_nets_a_review_of_platos_camera_by/">
Harper’s Fishing Nets: a review of Plato’s Camera by Paul Churchland
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/eli_sennesh">
eli_sennesh</a> |
11v (8c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mf0/monthly_bragging_thread_july_2015/">
Monthly Bragging Thread July 2015 </a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/elharo">
elharo</a> |
5v (8c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mez/rationality_quotes_thread_july_2015/">
Rationality Quotes Thread July 2015 </a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/elharo">
elharo</a> |
4v (27c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mbm/beyond_statistics_101/">
Beyond Statistics 101
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/JonahSinick">
JonahSinick</a> |
17v (124c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/md2/the_brain_as_a_universal_learning_machine/">
The Brain as a Universal Learning Machine
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/jacob_cannell">
jacob_cannell</a> |
74v (156c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mcz/intrinsic_motivation_is_crucial_for_overcoming/">
Intrinsic motivation is crucial for overcoming akrasia
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/JonahSinick">
JonahSinick</a> |
12v (43c)
</span>
</div>
</div></div>
</div>
<div class="spacer">
<div class="sidebox" id="side-quote">
<link href="./4_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./4_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2>
<a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/r/lesswrong/lw/mez/rationality_quotes_thread_july_2015/">Latest Rationality Quote</a>
</h2>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mez/rationality_quotes_thread_july_2015/cjmk?context=1#cjmk">&gt; And when your surpassing creations find the answers you asked for, you can't understand their analysis and you can't verify their answers. You have to take their word on faith —-
&gt; —- Or you use information theory to *flatten* it for you, to squash the tesseract into two dimensions and the Klein bottle into three, to simplify reality and pray to whatever Gods survived the millennium that your honorable twisting of the truth hasn't ruptured any of its load-bearing pylons. ...
&gt;I've never convinced myself that we made the right choice. I can cite the usual justifications in my sleep, talk endlessly about the rotational topology of information and the irrelevance of semantic comprehension. But after all the words, I'm still not sure. I don't know if anyone else is, either. Maybe it's just some grand consensual con, marks and players all in league. We won't admit that our creations are beyond us...
&gt;Maybe the Singularity happened years ago. We just don't want to admit we were left behind.
&gt; -- Siri Keeton explains what a "synthesist" does in *Blindsight* by Peter Watts, page 35-37
*Blindsight* is an amazingly Less Wrong book, with much discussion of epistemology and cognitive failures, starting with the title of the book. It is some of the hardest science fiction in existence, with a 22-page "Notes and References" section walking through 144 citations for the underlying science.
Pushing a related quote to a comment...
Pushing discussion to another comment...</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/Zubon">
<strong>Zubon</strong></a>
on
Rationality Quotes Thread July 2015  |
<span id="score_t1_cjmk">1 point</span>
</span>
</div></div>
</div>
<div class="spacer">
<div class="sidebox" id="recent-wiki-edits">
<h2><a href="https://web.archive.org/web/20160214232353/http://wiki.lesswrong.com/wiki/Special:RecentChanges">Recent Wiki Edits</a></h2>
<ul id="https://wiki.lesswrong.com/mediawiki/index.php?title=Special:RecentChanges&amp;feed=rss&amp;hideminor=1&amp;namespace=0"></ul>
</div>
</div>
<div class="spacer">
<div class="sidebox">
<h2 id="http://www.overcomingbias.com/feed_title"></h2>
<ul id="http://www.overcomingbias.com/feed"></ul>
</div>
</div>
<div class="spacer">
<div class="sidebox" id="side-monthly-contributors">
<link href="./4_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./4_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2>Top Contributors, 30 Days</h2>
<div class="contributors">
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/jacob_cannell">jacob_cannell</a>
(<b>1379</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/JonahSinick">JonahSinick</a>
(<b>643</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/abramdemski">abramdemski</a>
(<b>342</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Lumifer">Lumifer</a>
(<b>335</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/ChristianKl">ChristianKl</a>
(<b>287</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/DeVliegendeHollander">DeVliegendeHollander</a>
(<b>245</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/James_Miller">James_Miller</a>
(<b>209</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Lachouette">Lachouette</a>
(<b>185</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/eli_sennesh">eli_sennesh</a>
(<b>177</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Viliam">Viliam</a>
(<b>146</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Gunnar_Zarncke">Gunnar_Zarncke</a>
(<b>145</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/tanagrabeast">tanagrabeast</a>
(<b>134</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Vaniver">Vaniver</a>
(<b>120</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Kaj_Sotala">Kaj_Sotala</a>
(<b>117</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/gjm">gjm</a>
(<b>110</b>)
</div>
</div></div>
</div>
<div class="spacer">
<div class="sidebox" id="karma-awards">
<h2>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/karma">Recent Karma Awards</a>
</h2>
</div>
</div>
</div>
</div><!-- #main -->
<div class="footer clear">
<div class="reddit">
Powered by <strong>Reddit</strong>
<a href="https://web.archive.org/web/20160214232353/http://code.reddit.com/" title="Powered by Reddit"><img alt="Powered by Reddit" src="./4_files/reddit_logo.png"/></a>
</div>
<ul class="footer-links">
<li>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/about">About Less Wrong</a>
</li>
<li><a href="https://web.archive.org/web/20160214232353/https://github.com/tricycle/lesswrong/wiki/Issues,-Bugs,-and-Requested-Features">Report Issues</a></li>
<li class="privacy-policy"><a href="https://web.archive.org/web/20160214232353/http://intelligence.org/files/PrivacyandTerms-Lesswrong.com.pdf" target="_blank">Privacy &amp; Terms <span>(NEW 23/04/15)</span></a></li>
</ul>
</div>
<div class="cover" id="cover" onclick="hidecover('cover', 'loginpopup')" style="display:none">
</div>
<div class="popup" id="loginpopup" style="display: none">
<h1 id="cover_msg">You'll need to login or register to do that</h1>
<h2 id="cover_disclaim">(Don't worry, it only takes a few seconds)</h2>
<div class="loginform divide">
<h3>Create</h3>
<p class="tagline">
Pick a username and password for your Less Wrong and Less Wrong Wiki accounts. You will receive an email to verify your account.
</p>
<form action="https://web.archive.org/web/20160214232353/http://lesswrong.com/post/reg" id="login_reg" method="post" onsubmit="return chklogin(this);" target="_top">
<input name="reason" type="hidden" value=""/>
<input name="op" type="hidden" value="reg"/>
<div>
<ul>
<li>
<label for="user_reg">Username:</label>
<input id="user_reg" maxlength="20" name="user_reg" type="text" value=""/>
<span class="error" id="BAD_USERNAME_reg">
</span>
<span class="error" id="BAD_USERNAME_CHARS_reg">
</span>
<span class="error" id="BAD_USERNAME_SHORT_reg">
</span>
<span class="error" id="BAD_USERNAME_LONG_reg">
</span>
<span class="error" id="USERNAME_TAKEN_reg">
</span>
</li>
<li>
<label for="email_reg">Email:</label>
<input id="email_reg" maxlength="50" name="email_reg" type="text" value=""/>
<span class="error" id="NO_EMAIL_reg">
</span>
<span class="error" id="BAD_EMAIL_reg">
</span>
</li>
<li>
<label for="passwd_reg">Password:</label>
<input id="passwd_reg" maxlength="20" name="passwd_reg" type="password"/>
<span class="error" id="BAD_PASSWORD_reg">
</span>
</li>
<li>
<label for="passwd2_reg">Verify password:</label>
<input id="passwd2_reg" maxlength="20" name="passwd2_reg" type="password"/>
<span class="error" id="BAD_PASSWORD_MATCH_reg">
</span>
</li>
<li>
<table>
<tbody><tr>
<td></td>
<td>
<img alt="i wonder if these things even work" class="capimage" id="capimage" src="./4_files/kill.png"/>
</td>
</tr>
<tr>
<td align="right">
</td>
<td>
<input id="capiden" name="iden" type="hidden" value=""/>
<input class="cap-text" id="captcha" name="captcha" onfocus="clearTitle(this)" size="30" style="color: gray;" type="text"/>
</td>
<td>
<span class="error" id="BAD_CAPTCHA">
</span>
</td>
</tr>
</tbody></table>
<span class="error" id="DRACONIAN_reg">
</span>
<span class="error" id="RATELIMIT_reg">
</span>
</li>
<li>
<input id="rem_reg" name="rem" type="checkbox"/>
<label class="remember" for="rem_reg">Remember me</label>
</li>
</ul>
<p>
<button type="submit">
Create account
</button>
<span class="error" id="status_reg"></span>
</p>
</div>
</form>
</div>
<div class="loginform">
<h3>Login</h3>
<p class="tagline">
Already have an account and just want to login?
</p>
<form action="https://web.archive.org/web/20160214232353/http://lesswrong.com/post/login" id="login_login" method="post" onsubmit="return chklogin(this);" target="_top">
<input name="reason" type="hidden" value=""/>
<input name="op" type="hidden" value="login"/>
<div>
<ul>
<li>
<label for="user_login">Username:</label>
<input id="user_login" maxlength="20" name="user_login" type="text" value=""/>
</li>
<li>
<label for="passwd_login">Password:</label>
<input id="passwd_login" maxlength="20" name="passwd_login" type="password"/>
<span class="error" id="WRONG_PASSWORD_login">
</span>
</li>
<li>
<input id="rem_login" name="rem" type="checkbox"/>
<label class="remember" for="rem_login">Remember me</label>
</li>
</ul>
<p>
<button type="submit">
Login
</button>
<span class="error" id="status_login"></span>
</p>
</div>
</form>
<p>
<a href="https://web.archive.org/web/20160214232353/http://lesswrong.com/password">Forgot your password?</a>
</p>
</div>
<div class="clear"></div>
<div style="text-align:center">
<a href="javascript:hidecover('cover','loginpopup')">
Close this window
</a>
</div>
</div>
<div class="cover" id="langcover" onclick="hidecover('langcover', 'langpopup')" style="display:none">
</div>
<div class="popup" id="langpopup" style="display: none">
<div style="text-align:center">
<a href="javascript:hidecover('langcover','langpopup')">
Close this window
</a>
</div>
</div>
</div><!-- #wrapper -->
</body><div></div></html>
