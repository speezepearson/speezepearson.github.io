<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<!-- saved from url=(0105)https://web.archive.org/web/20170430210048/http://lesswrong.com/lw/dgc/interlude_for_behavioral_economics -->
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml"><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<link href="./5_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include -->
<title>
Interlude for Behavioral Economics - Less Wrong
</title>
<meta content="
rationality, optimal philanthropy, critical thinking, heuristics and biases, skeptic
" name="keywords"/>
<meta content="
Interlude for Behavioral Economics - Less Wrong
" name="title"/>
<meta content="The so-called “rational” solutions to the Prisoners' Dilemma and Ultimatum Game are suboptimal to say the least. Humans have various kludges added by both natur" name="description"/>
<!-- Start Visual Website Optimizer Asynchronous Code -->
<!-- End Visual Website Optimizer Asynchronous Code -->
<!--[if lte IE 8]>
<script src="/static/ie8below.js?v=(stdin)= 78e6f09c93f01df69ddef0ced465a511" type="text/javascript"></script>
<![endif]-->
<link href="./5_files/main.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/Stylesheet" rel="stylesheet" type="text/css"/>
<link href="./5_files/lesswrong.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/jquery.qtip.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/lesswrong-mod.css" rel="stylesheet" type="text/css"/>
<!--[if lte IE 8]>
<link rel="stylesheet" type="text/css" href="/static/ie8below.css?v=(stdin)= 211a53181ad64730403441f5147876f4" />
<![endif]-->
<!--[if lte IE 7]>
<link rel="stylesheet" type="text/css" href="/static/ie7below.css?v=(stdin)= b43edf2e0f3764458e9118be01eab834" />
<![endif]-->
<!--[if IE 7]>
<link rel="stylesheet" type="text/css" href="/static/ie7.css?v=(stdin)= d41d8cd98f00b204e9800998ecf8427e" />
<![endif]-->
<!--[if lte IE 6]>
<link rel="stylesheet" type="text/css" href="/static/ie6.css?v=(stdin)= 8057c056f59a32b0740514cbe26ea377" />
<![endif]-->
<link href="https://web.archive.org/web/20170430210048im_/http://lesswrong.com/static/favicon.ico" rel="shortcut icon" type="image/x-icon"/>
<link href="https://web.archive.org/web/20170430210048/http://lesswrong.com/lw/dgc/interlude_for_behavioral_economics/.rss" rel="alternate" title="RSS" type="application/rss+xml"/>
</head>
<body class="post" onclick="close_menus()">
<style type="text/css">
body {
  margin-top:0 !important;
  padding-top:0 !important;
  min-width:800px !important;
}
.wb-autocomplete-suggestions {
    text-align: left; cursor: default; border: 1px solid #ccc; border-top: 0; background: #fff; box-shadow: -1px 1px 3px rgba(0,0,0,.1);
    position: absolute; display: none; z-index: 2147483647; max-height: 254px; overflow: hidden; overflow-y: auto; box-sizing: border-box;
}
.wb-autocomplete-suggestion { position: relative; padding: 0 .6em; line-height: 23px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; font-size: 1.02em; color: #333; }
.wb-autocomplete-suggestion b { font-weight: bold; }
.wb-autocomplete-suggestion.selected { background: #f0f0f0; }
</style>
<div class="wb-autocomplete-suggestions " style="left: 366px; top: 550px; width: 404px;"></div>
<!-- END WAYBACK TOOLBAR INSERT -->
<div id="wrapper">
<div class="lesswrong" id="header">
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/" id="logo">
<img alt="Less Wrong" id="header-img" src="./5_files/logo_trans.png"/>
</a>
<img alt="A community blog devoted to refining the art of human rationality" id="tagline" src="./5_files/tagline.png"/>
<a href="https://web.archive.org/web/20170430210048/http://www.fhi.ox.ac.uk/" id="fhi" target="_blank">Future of Humanity Institute</a>
<a href="https://web.archive.org/web/20170430210048/http://intelligence.org/" id="miri" target="_blank">Machine Intelligence Research Institute</a>
<a href="https://web.archive.org/web/20170430210048/http://rationality.org/" id="cfar" target="_blank">Center for Applied Rationality</a>
</div><!-- #header -->
<div class="clear" id="main">
<div class="clear " id="content">
<ul class="clear" id="nav">
<li class="active">
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/promoted/">Main</a>
<img alt="" class="dropdown" src="./5_files/nav-dropdown.gif"/>
<ul>
<li>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/promoted/">Posts</a>
</li>
<li>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/comments/">Comments</a>
</li>
</ul>
</li>
<li>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/r/discussion/new/">Discussion</a>
<img alt="" class="dropdown" src="./5_files/nav-dropdown.gif"/>
<ul>
<li>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/r/discussion/new/">Posts</a>
</li>
<li>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/r/discussion/comments/">Comments</a>
</li>
</ul>
</li>
</ul>
<div class="sitetable" id="siteTable">
<div class="ajaxhook" id="ajaxHook">
</div>
<div class="post editors-pick" id="thingrow_t3_dgc" itemscope="" itemtype="http://schema.org/BlogPosting">
<h1 itemprop="name"><a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/lw/dgc/interlude_for_behavioral_economics/">
Interlude for Behavioral Economics
</a>
</h1>
<div class="meta clear">
<span class="votes">
<span class="votes " id="score_t3_dgc" oldtitle="96% positive">
50
</span>
</span>
<span class="author">
<span class="hide-text">Post author:</span>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/user/Yvain/" id="author_t3_dgc">Yvain</a>
</span>
<span class="date">06 July 2012 08:12PM</span>
</div><!-- .meta -->
<div class="content clear" id="entry_t3_dgc">
<div class="md">
<div itemprop="description">
<div><p>The so-called “rational” solutions to the Prisoners' Dilemma and Ultimatum Game are suboptimal to say the least. Humans have various kludges added by both nature or nurture to do better, but they're not perfect and they're certainly not simple. They leave entirely open the question of what real people will actually do in these situations, a question which can only be addressed by hard data.</p>
<p><a id="more"></a></p>
<p>As in so many other areas, our most important information comes from reality television. <a href="https://web.archive.org/web/20170430210048/http://www.amazon.com/The-Art-Strategy-Theorists-Business/dp/0393062430"><em>The Art of Strategy</em></a> discusses a US game show “Friend or Foe” where a team of two contestants earned money by answering trivia questions. At the end of the show, the team used a sort-of Prisoner's Dilemma to split their winnings: each team member chose “Friend” (cooperate) or “Foe” (defect). If one player cooperated and the other defected, the defector kept 100% of the pot. If both cooperated, each kept 50%. And if both defected, neither kept anything (this is a significant difference from the standard dilemma, where a player is a little better off defecting than cooperating if her opponent defects). <br/><br/>Players chose “Friend” about 45% of the time. Significantly, this number remained constant despite the size of the pot: they were no more likely to cooperate when splitting small amounts of money than large. <br/><br/>Players seemed to want to play “Friend” if and only if they expected their opponents to do so. This is not rational, but it accords with the “Tit-for-Tat” strategy hypothesized to be the evolutionary solution to Prisoner's Dilemma. This played out on the show in a surprising way: players' choices started off random, but as the show went on and contestants began participating who had seen previous episodes, they began to base their decision on observable characteristics about their opponents. For example, in the first season women cooperated more often than men, so by the second season a player was cooperating more often if their opponent was a woman - whether or not that player was a man or woman themselves. <br/><br/>Among the superficial characteristics used, the only one to reach statistical significance <a href="https://web.archive.org/web/20170430210048/https://docs.google.com/viewer?a=v&amp;q=cache:JRe4dpT-siQJ:bpp.wharton.upenn.edu/mawhite/Papers/FriendorFoe.pdf+&amp;hl=en&amp;gl=us&amp;pid=bl&amp;srcid=ADGEESjeRJCRI-h9qVGveKoOdAJHIP7U6eI86_1xhqdmuTsWrywbCF3IbpD3K6_i7nhqM9bSFouAM4vuNKbDrxjnZjUAfth3j8ztDy5g-QQ_IUVYPX6l0QDPoFDzlliMzL4jG5x8Z2Yd&amp;sig=AHIEtbSl0cC2MvFPFFnjXC6-O-K8Z8FOqw">according to the study</a> was age: players below the median age of 27 played “Foe” more often than those over it (65% vs. 39%, p &lt; .001). Other nonsignificant tendencies were for men to defect more than women (53% vs. 46%, p=.34) and for black people to defect more than white people (58% vs. 48%, p=.33). These nonsignificant tendencies became important because the players themselves attributed significance to them: for example, by the second season women were playing “Foe” 60% of the time against men but only 45% of the time against women (p&lt;.01) presumably because women were perceived to be more likely to play “Friend” back; also during the second season, white people would play “Foe” 75% against black people, but only 54% of the time against other white people.<br/><br/>(This risks self-fulfilling prophecies. If I am a black man playing a white woman, I expect she will expect me to play “Foe” against her, and she will “reciprocate” by playing “Foe” herself. Therefore, I may choose to “reciprocate” against her by playing “Foe” myself, even if I wasn't originally intending to do so, and other white women might observe this, thus creating a vicious cycle.)<br/><br/>In any case, these attempts at coordinated play worked, but only imperfectly. By the second season, 57% of pairs chose the same option - either (C, C) or (D, D). <br/><br/>Art of Strategy included another great Prisoner's Dilemma experiment. In this one, the experimenters spoiled the game: they told both players that they would be deciding simultaneously, but in fact, they let Player 1 decide first, and then secretly approached Player 2 and told her Player 1's decision, letting Player 2 consider this information when making her own choice. <br/><br/>Why should this be interesting? From the previous data, we know that humans play “tit-for-expected-tat”: they will generally cooperate if they believe their opponent will cooperate too. We can come up with two hypotheses to explain this behavior. First, this could be a folk version of Timeless Decision Theory or Hofstadter's superrationality; a belief that their own decision literally determines their opponent's decision. Second, it could be based on a belief in fairness: if I think my opponent cooperated, it's only decent that I do the same.<br/><br/>The “researchers spoil the setup” experiment can distinguish between these two hypotheses. If people believe their choice determines that of their opponent, then once they know their opponent's choice they no longer have to worry and can freely defect to maximize their own winnings. But if people want to cooperate to reward their opponent, then learning that their opponent cooperated for sure should only increase their willingness to reciprocate.<br/><br/>The results: If you tell the second player that the first player defected, 3% still cooperate (apparently 3% of people are Jesus). If you tell the second player that the first player cooperated.........only 16%  cooperate. When the same researchers in the same lab didn't tell the second player anything, 37% cooperated.<br/><br/>This is a pretty resounding victory for the “folk version of superrationality” hypothesis. 21% of people wouldn't cooperate if they heard their opponent defected, wouldn't cooperate if they heard their opponent cooperated, but will cooperate if they don't know which of those two their opponent played.<br/><br/>Moving on to the Ultimatum Game: very broadly, the first player usually offers between 30 and 50 percent, and the second player tends to accept. If the first player offers less than about 20 percent, the second player tends to reject it. <br/><br/>Like the Prisoner's Dilemma, the amount of money at stake doesn't seem to matter. This is really surprising! Imagine you played an Ultimatum Game for a billion dollars. The first player proposes $990 million for herself, $10 million for you. On the one hand, this is a 99-1 split, just as unfair as $99 versus $1. On the other hand, ten million dollars! <br/><br/>Although tycoons have yet to donate a billion dollars to use for Ultimatum Game experiments, researchers have done the next best thing and flown out to Third World countries where even $100 can be an impressive amount of money. In games in Indonesia played for a pot containing a sixth of Indonesians' average yearly income, Indonesians still rejected unfair offers. In fact, at these levels the first player tended to propose fairer deals than at lower stakes - maybe because it would be a disaster if her offer get rejected.<br/><br/>It was originally believed that results in the Ultimatum Game were mostly independent of culture.  Groups in the US, Israel, Japan, Eastern Europe, and Indonesia all got more or less the same results. But this elegant simplicity was, like so many other things, ruined by the Machiguenga Indians of eastern Peru. They tend to make offers around 25%, and will accept pretty much anything. <br/><br/>One more interesting finding: people who accept low offers in the Ultimatum Game <a href="https://web.archive.org/web/20170430210048/http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1950304/">have lower testosterone</a> than those who reject them.<br/><br/>There is a certain degenerate form of the Ultimatum Game called the Dictator Game. In the Dictator Game, the second player doesn't have the option of vetoing the first player's distribution. In fact, the second player doesn't do anything at all; the first player distributes the money, both players receive the amount of money the first player decided upon, and the game ends. A perfectly selfish first player would take 100% of the money in the Dictator Game, leaving the second player with nothing.<br/><br/>In <a href="https://web.archive.org/web/20170430210048/http://www.coll.mpg.de/pdf_dat/2010_07online.pdf">a metaanalysis of 129 papers consisting of over 41,000 individual games</a>, the average amount the first player gave the second player was 28.35%. 36% of first players take everything, 17% divide the pot equally, and 5% give everything to the second player, nearly doubling our previous estimate of what percent of people are Jesus.<br/><br/>The meta-analysis checks many different results, most of which are insignificant, but a few stand out. Subjects playing the dictator game “against” a charity are much more generous; up to a quarter give everything. When the experimenter promises to “match” each dollar given away (eg the dictator gets $100, but if she gives it to the second player the second player gets $200), the dictator gives much more (somewhat surprising, as this might be an excuse to keep $66 for yourself and get away with it by claiming that both players still got equal money). On the other hand, if the experimenters give the second player a free $100, so that they start off richer than the dictator, the dictator compensates by not giving them nearly as much money. <br/><br/>Old people give more than young people, and non-students give more than students. People from “primitive” societies give more than people from more developed societies, and the more primitive the society, the stronger the effect.  The most important factor, though? As always, sex. Women both give more and get more in dictator games.<br/><br/>It is somewhat inspiring that so many people give so much in this game, but before we become too excited about the fundamental goodness of humanity, Art of Strategy mentions <a href="https://web.archive.org/web/20170430210048/http://papers.ssrn.com/sol3/papers.cfm?abstract_id=494422">a great experiment by Dana, Cain, and Dawes</a>. The subjects were offered a choice: either play the Dictator Game with a second player for $10, or get $9 and the second subject is sent home and never even knows what the experiment is about. A third of participants took the second option.<br/><br/>So generosity in the Dictator Game isn't always about wanting to help other people. It seems to be about knowing, deep down, that some anonymous person who probably doesn't even know your name and who will never see you again is disappointed in you. Remove the little problem of the other person knowing what you did, and they will not only keep the money, but even be willing to pay the experiment a dollar to keep them quiet.</p></div>
</div>
</div>
</div><!-- .content -->
<div class="articlenavigation">
<h4><a class="dsphead" href="javascript:void(0)" id="articlenavstate" onclick="toggle_article_navigation('dgc')">Article Navigation</a></h4>
<div class="dspcont" id="article_nav_controls" style="display: none;">
<span class="loading"><img alt="" src="./5_files/ajax-loader.gif"/>
Loading…</span>
</div>
</div><!-- .articlenavigation -->
<div class="tools clear">
<div class="vote" id="arrows_t3_dgc" style="display:none">
<a class="up" id="up_t3_dgc" oldtitle="Vote up" onclick="showcover(true, 'vote_t3_dgc')">Vote up</a>
<a class="down" id="down_t3_dgc" oldtitle="Vote down" onclick="showcover(true, 'vote_t3_dgc')">Vote down</a>
<span class="loading" id="votespinner_t3_dgc"><img alt="" src="./5_files/ajax-loader.gif"/></span>
</div>
<a class="comment" href="https://web.archive.org/web/20170430210048/http://lesswrong.com/lw/dgc/interlude_for_behavioral_economics/#comments">Comments (49)</a>
<div class="boxright clear">
<ul class="clear">
</ul>
<div class="tags">
<span>Tags:</span>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/tag/game_theory/">game_theory</a>
<span class="separator"> </span>
</div>
</div>
<span class="error" id="status_t3_dgc" style="display: none;"></span>
</div><!-- .tools -->
</div><!-- .post -->
</div>

</div>
<div id="sidebar">
<ul class="clear" id="rightnav">
<li>
<a href="https://web.archive.org/web/20170430210048/http://wiki.lesswrong.com/">wiki</a>
</li>
<li>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/sequences/">Sequences</a>
</li>
<li>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/about/">About</a>
</li>
</ul>
<div class="spacer">
<div class="sidebox" id="side-search">
<form action="https://web.archive.org/web/20170430210048/http://lesswrong.com/search/results" id="cse-search-box" onsubmit="return true;">
<div>
<input name="cx" type="hidden" value="015839050583929870010:-802ptn4igi"/>
<input name="cof" type="hidden" value="FORID:11"/>
<input name="ie" type="hidden" value="UTF-8"/>
<input class="text" id="search-query" name="q" placeholder="Custom Search" size="31" style='background: url("https://www.google.com/cse/static/images/1x/googlelogo_lightgrey_46x16dp.png") left center no-repeat rgb(255, 255, 255); text-indent: 48px;' type="text"/>
<input class="submit" name="sa" type="submit" value="Search"/>
</div>
<input name="siteurl" type="hidden" value="web.archive.org/web/20170430210048/http://lesswrong.com/lw/dgc/interlude_for_behavioral_economics"/><input name="ref" type="hidden" value="web.archive.org/web/20160701000000*/http://lesswrong.com/lw/dgc/interlude_for_behavioral_economics"/><input name="ss" type="hidden" value=""/></form>
<form style="display:none">
<input id="cse-search-transformed" type="hidden" value="0"/>
</form>
</div><!-- #side-search -->
</div>
<div class="spacer">
<div class="sidebox" id="side-login">
<form action="https://web.archive.org/web/20170430210048/http://lesswrong.com/post/login" class="login-form-side" method="post" onsubmit="return chklogin(this);">
<div class="row">
<label for="username">
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/" onclick="return showcover(false);">Register</a>
/ Login</label>
<input name="op" type="hidden" value="login-main"/>
<input id="username" maxlength="20" name="user_login" tabindex="1" type="text"/>
</div>
<div class="row">
<label for="password">Password</label>
<input id="password" maxlength="20" name="passwd_login" tabindex="2" type="password"/>
</div>
<div class="row">
<div id="remember-me">
<label for="rem-login-main">Remember me</label>
<input id="rem-login-main" name="rem" tabindex="3" type="checkbox"/>
</div>
</div>
<div>
<div class="error" id="WRONG_PASSWORD_login-main">
</div>
<div class="error" id="status_login-main"></div>
</div>
<div class="row">
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/password" id="recover">Recover password</a>
<button class="btn" tabindex="4" type="submit">Login</button>
</div>
</form>
</div>
</div>
<div class="spacer">
<div class="sidebox" id="side-feed">
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/lw/dgc/interlude_for_behavioral_economics/.rss">
<img alt="Feed icon" src="./5_files/feed.png"/>
Subscribe to RSS Feed
</a>
</div>
</div>
<div class="spacer">
<div class="sidebox" id="side-meetups">
<link href="./5_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2 class="meetup-title">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/meetups">Nearest Meetups</a>
</h2>
<ul>
<li>
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/meetups/1f8">
San Antonio, TX: <span class="date">12 July 2015 01:30PM</span>
</a>
</li>
<li>
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/meetups/18x">
Durham, NC (RTLW) Discussion Meetup: <span class="date">02 July 2026 07:00PM</span>
</a>
</li>
</ul></div>
</div>
<div class="spacer">
<div class="sidebox" id="side-studyroom">
<h2 class="studyroom-title">
<a href="https://web.archive.org/web/20170430210048/https://complice.co/room/lesswrong">Virtual Study Room</a>
</h2>
Co-work with other rationalists online.<br/>
<ul>
<li>
<a href="https://web.archive.org/web/20170430210048/https://complice.co/room/lesswrong"><strong>Less Wrong Study Hall</strong>
</a>
</li>
</ul>
</div>
</div>
<div class="spacer">
<div class="sidebox" id="side-comments">
<link href="./5_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2>
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/comments">Recent Comments</a>
</h2>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/lx/argument_screens_off_authority/cjxg?context=1#cjxg">&gt;We observe that politicians are happy to cut taxes (for people who can benefit them) if they personally get paid as much or more than before. Why would it be otherwise? Having the ability to take and redistribute someone else's money provides a concentrated benefit to the one doing the taking and redistributing. Cutting taxes produces a much more diffuse benefit. Concentrated benefits lead to Machiavellian behavior much more than diffuse benefits. It is possible, of course, to have an anti-taxes lobbying group which provides a concentrated benefit, but the overall balance between concentrated and diffuse benefits is on the side of the higher taxes.
&gt;(And any long-term interest, eg power for their family, should take the state of their civilization into account.)
That would be a diffuse cost. The politician may care about the portion of the diffuse effectthat affects his family, but that's only a small portion of the total. If the politician makes policy based on which costs help him and his family and which ones hurt him and his family, the concentrated ones will win. The ones that affect all civilization, a small portion of which he actually cares about because it goes to his family, will lose.</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Jiro">
<strong>Jiro</strong></a>
on
Argument Screens Off Authority |
<span id="score_t1_cjxg">0 points</span>
</span>
</div>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/1jm/getting_over_dust_theory/cjx9?context=1#cjx9">&gt; don't think there's a meaningful difference between "the real world" and a perfect simulation of it (at least seen "from the inside") -
What's the meaning of meaningful? Do you mean that you literally cannot understand the opposite of simulationism? Or are using "meaningful" to mean "empirically confirmable"? The empirical indetectability of a simulation follows from simulations premises, right enough....but it cannot be used to argue for them.</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/TheAncientGeek">
<strong>TheAncientGeek</strong></a>
on
Getting Over Dust Theory |
<span id="score_t1_cjx9">0 points</span>
</span>
</div>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/1sm/akrasia_tactics_review/cjwp?context=1#cjwp">**Missing techniques:**
* [caching your identity](http://lesswrong.com/lw/4e/cached_selves/)
* [goal factoring](http://lesswrong.com/lw/8gv/the_curse_of_identity/)
* [solutions for the human memory problem sets in the comments](http://lesswrong.com/lw/iwq/human_memory_problem_set/)
* [insight into procrastination, which is spread over several posts including this link](http://lesswrong.com/lw/3kv/working_hurts_less_than_procrastinating_we_fear/)
* [Preempting excuses](http://lesswrong.com/lw/24o/eight_short_studies_on_excuses/)
**both missing reviews and missing a write up on Lesswrong**
* [SOBER technique](http://smartrecoveryaustralia.com.au/s-o-b-e-r/)
**Techniques I've tried and will put up a review for soon hopefully:**
* [check cosequentialism](http://lesswrong.com/lw/b4f/sotw_check_consequentialism/)</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Clarity">
<strong>Clarity</strong></a>
on
Akrasia Tactics Review |
<span id="score_t1_cjwp">1 point</span>
</span>
</div>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/mgi/rational_vs_reasonable/cjwm?context=1#cjwm">I'd like to become a more reasonable person. How do I change my mindset to make such behaviors more common?</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/27chaos">
<strong>27chaos</strong></a>
on
Rational vs Reasonable |
<span id="score_t1_cjwm">0 points</span>
</span>
</div>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/lw/lx/argument_screens_off_authority/cjwa?context=1#cjwa">No, you did not. A Machiavellan politician wants to stay in power, that is, to be elected. You're asserting a group interest that does not exist. We observe that politicians are happy to cut taxes (for people who can benefit them) if they personally get paid as much or more than before. Why would it be otherwise? (And any long-term interest, eg power for their family, should take the state of their civilization into account.)</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/hairyfigment">
<strong>hairyfigment</strong></a>
on
Argument Screens Off Authority |
<span id="score_t1_cjwa">0 points</span>
</span>
</div></div>
</div>
<div class="spacer">
<div class="sidebox" id="side-posts">
<link href="./5_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2>
<a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/recentposts">Recent Posts</a>
</h2>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mgi/rational_vs_reasonable/">
Rational vs Reasonable
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/abramdemski">
abramdemski</a> |
6v (1c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mgh/new_lw_meetup_kyiv/">
New LW Meetup: Kyiv
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/FrankAdamek">
FrankAdamek</a> |
1v (0c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mft/european_community_weekend_2015_followup/">
European Community Weekend 2015 - Followup
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/Lachouette">
Lachouette</a> |
16v (7c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/me1/the_unfriendly_superintelligence_next_door/">
The Unfriendly Superintelligence next door
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/jacob_cannell">
jacob_cannell</a> |
40v (63c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mf7/harpers_fishing_nets_a_review_of_platos_camera_by/">
Harper’s Fishing Nets: a review of Plato’s Camera by Paul Churchland
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/eli_sennesh">
eli_sennesh</a> |
11v (8c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mf0/monthly_bragging_thread_july_2015/">
Monthly Bragging Thread July 2015 </a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/elharo">
elharo</a> |
5v (8c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mez/rationality_quotes_thread_july_2015/">
Rationality Quotes Thread July 2015 </a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/elharo">
elharo</a> |
4v (27c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mbm/beyond_statistics_101/">
Beyond Statistics 101
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/JonahSinick">
JonahSinick</a> |
17v (124c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/md2/the_brain_as_a_universal_learning_machine/">
The Brain as a Universal Learning Machine
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/jacob_cannell">
jacob_cannell</a> |
74v (156c)
</span>
</div>
</div>
<div class="reddit-link">
<div>
<h3>
<a class="reddit-link-title" href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mcz/intrinsic_motivation_is_crucial_for_overcoming/">
Intrinsic motivation is crucial for overcoming akrasia
</a>
</h3>
<span>by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/JonahSinick">
JonahSinick</a> |
12v (43c)
</span>
</div>
</div></div>
</div>
<div class="spacer">
<div class="sidebox" id="side-quote">
<link href="./5_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2>
<a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/r/lesswrong/lw/mez/rationality_quotes_thread_july_2015/">Latest Rationality Quote</a>
</h2>
<div class="inline-comment">
<h3><a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/lw/mez/rationality_quotes_thread_july_2015/cjmk?context=1#cjmk">&gt; And when your surpassing creations find the answers you asked for, you can't understand their analysis and you can't verify their answers. You have to take their word on faith —-
&gt; —- Or you use information theory to *flatten* it for you, to squash the tesseract into two dimensions and the Klein bottle into three, to simplify reality and pray to whatever Gods survived the millennium that your honorable twisting of the truth hasn't ruptured any of its load-bearing pylons. ...
&gt;I've never convinced myself that we made the right choice. I can cite the usual justifications in my sleep, talk endlessly about the rotational topology of information and the irrelevance of semantic comprehension. But after all the words, I'm still not sure. I don't know if anyone else is, either. Maybe it's just some grand consensual con, marks and players all in league. We won't admit that our creations are beyond us...
&gt;Maybe the Singularity happened years ago. We just don't want to admit we were left behind.
&gt; -- Siri Keeton explains what a "synthesist" does in *Blindsight* by Peter Watts, page 35-37
*Blindsight* is an amazingly Less Wrong book, with much discussion of epistemology and cognitive failures, starting with the title of the book. It is some of the hardest science fiction in existence, with a 22-page "Notes and References" section walking through 144 citations for the underlying science.
Pushing a related quote to a comment...
Pushing discussion to another comment...</a></h3>
<span class="tagline">
by <a href="https://web.archive.org/web/20150711171926/http://lesswrong.com/user/Zubon">
<strong>Zubon</strong></a>
on
Rationality Quotes Thread July 2015  |
<span id="score_t1_cjmk">1 point</span>
</span>
</div></div>
</div>
<div class="spacer">
<div class="sidebox" id="recent-wiki-edits">
<h2><a href="https://web.archive.org/web/20170430210048/http://wiki.lesswrong.com/wiki/Special:RecentChanges">Recent Wiki Edits</a></h2>
<ul id="https://wiki.lesswrong.com/mediawiki/index.php?title=Special:RecentChanges&amp;feed=rss&amp;hideminor=1&amp;namespace=0"></ul>
</div>
</div>
<div class="spacer">
<div class="sidebox">
<h2 id="http://www.overcomingbias.com/feed_title"></h2>
<ul id="http://www.overcomingbias.com/feed"></ul>
</div>
</div>
<div class="spacer">
<div class="sidebox" id="side-monthly-contributors">
<link href="./5_files/banner-styles.css" rel="stylesheet" type="text/css"/>
<link href="./5_files/iconochive.css" rel="stylesheet" type="text/css"/>
<!-- End Wayback Rewrite JS Include --><h2>Top Contributors, 30 Days</h2>
<div class="contributors">
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/jacob_cannell">jacob_cannell</a>
(<b>1379</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/JonahSinick">JonahSinick</a>
(<b>643</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/abramdemski">abramdemski</a>
(<b>342</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Lumifer">Lumifer</a>
(<b>335</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/ChristianKl">ChristianKl</a>
(<b>287</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/DeVliegendeHollander">DeVliegendeHollander</a>
(<b>245</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/James_Miller">James_Miller</a>
(<b>209</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Lachouette">Lachouette</a>
(<b>185</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/eli_sennesh">eli_sennesh</a>
(<b>177</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Viliam">Viliam</a>
(<b>146</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Gunnar_Zarncke">Gunnar_Zarncke</a>
(<b>145</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/tanagrabeast">tanagrabeast</a>
(<b>134</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Vaniver">Vaniver</a>
(<b>120</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/Kaj_Sotala">Kaj_Sotala</a>
(<b>117</b>)
</div>
<div class="user">
<a href="https://web.archive.org/web/20150711171848/http://lesswrong.com/user/gjm">gjm</a>
(<b>110</b>)
</div>
</div></div>
</div>
<div class="spacer">
<div class="sidebox" id="karma-awards">
<h2>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/karma">Recent Karma Awards</a>
</h2>
</div>
</div>
</div>
</div><!-- #main -->
<div class="footer clear">
<div class="reddit">
Powered by <strong>Reddit</strong>
<a href="https://web.archive.org/web/20170430210048/http://code.reddit.com/" title="Powered by Reddit"><img alt="Powered by Reddit" src="./5_files/reddit_logo.png"/></a>
</div>
<ul class="footer-links">
<li>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/about">About Less Wrong</a>
</li>
<li><a href="https://web.archive.org/web/20170430210048/https://github.com/tricycle/lesswrong/wiki/Issues,-Bugs,-and-Requested-Features">Report Issues</a></li>
<li class="privacy-policy"><a href="https://web.archive.org/web/20170430210048/http://intelligence.org/files/PrivacyandTerms-Lesswrong.com.pdf" target="_blank">Privacy &amp; Terms</a></li>
</ul>
</div>
<div class="cover" id="cover" onclick="hidecover('cover', 'loginpopup')" style="display:none">
</div>
<div class="popup" id="loginpopup" style="display: none">
<h1 id="cover_msg">You'll need to login or register to do that</h1>
<h2 id="cover_disclaim">(Don't worry, it only takes a few seconds)</h2>
<div class="loginform divide">
<h3>Create</h3>
<p class="tagline">
Pick a username and password for your Less Wrong and Less Wrong Wiki accounts. You will receive an email to verify your account.
</p>
<form action="https://web.archive.org/web/20170430210048/http://lesswrong.com/post/reg" id="login_reg" method="post" onsubmit="return chklogin(this);" target="_top">
<input name="reason" type="hidden" value=""/>
<input name="op" type="hidden" value="reg"/>
<div>
<ul>
<li>
<label for="user_reg">Username:</label>
<input id="user_reg" maxlength="20" name="user_reg" type="text" value=""/>
<span class="error" id="BAD_USERNAME_reg">
</span>
<span class="error" id="BAD_USERNAME_CHARS_reg">
</span>
<span class="error" id="BAD_USERNAME_SHORT_reg">
</span>
<span class="error" id="BAD_USERNAME_LONG_reg">
</span>
<span class="error" id="USERNAME_TAKEN_reg">
</span>
</li>
<li>
<label for="email_reg">Email:</label>
<input id="email_reg" maxlength="50" name="email_reg" type="text" value=""/>
<span class="error" id="NO_EMAIL_reg">
</span>
<span class="error" id="BAD_EMAIL_reg">
</span>
</li>
<li>
<label for="passwd_reg">Password:</label>
<input id="passwd_reg" maxlength="20" name="passwd_reg" type="password"/>
<span class="error" id="BAD_PASSWORD_reg">
</span>
</li>
<li>
<label for="passwd2_reg">Verify password:</label>
<input id="passwd2_reg" maxlength="20" name="passwd2_reg" type="password"/>
<span class="error" id="BAD_PASSWORD_MATCH_reg">
</span>
</li>
<li>
<table>
<tbody><tr>
<td></td>
<td>
<img alt="i wonder if these things even work" class="capimage" id="capimage" src="./5_files/kill.png"/>
</td>
</tr>
<tr>
<td align="right">
</td>
<td>
<input id="capiden" name="iden" type="hidden" value=""/>
<input class="cap-text" id="captcha" name="captcha" onfocus="clearTitle(this)" size="30" style="color: gray;" type="text"/>
</td>
<td>
<span class="error" id="BAD_CAPTCHA">
</span>
</td>
</tr>
</tbody></table>
<span class="error" id="DRACONIAN_reg">
</span>
<span class="error" id="RATELIMIT_reg">
</span>
</li>
<li>
<input id="rem_reg" name="rem" type="checkbox"/>
<label class="remember" for="rem_reg">Remember me</label>
</li>
</ul>
<p>
<button type="submit">
Create account
</button>
<span class="error" id="status_reg"></span>
</p>
</div>
</form>
</div>
<div class="loginform">
<h3>Login</h3>
<p class="tagline">
Already have an account and just want to login?
</p>
<form action="https://web.archive.org/web/20170430210048/http://lesswrong.com/post/login" id="login_login" method="post" onsubmit="return chklogin(this);" target="_top">
<input name="reason" type="hidden" value=""/>
<input name="op" type="hidden" value="login"/>
<div>
<ul>
<li>
<label for="user_login">Username:</label>
<input id="user_login" maxlength="20" name="user_login" type="text" value=""/>
</li>
<li>
<label for="passwd_login">Password:</label>
<input id="passwd_login" maxlength="20" name="passwd_login" type="password"/>
<span class="error" id="WRONG_PASSWORD_login">
</span>
</li>
<li>
<input id="rem_login" name="rem" type="checkbox"/>
<label class="remember" for="rem_login">Remember me</label>
</li>
</ul>
<p>
<button type="submit">
Login
</button>
<span class="error" id="status_login"></span>
</p>
</div>
</form>
<p>
<a href="https://web.archive.org/web/20170430210048/http://lesswrong.com/password">Forgot your password?</a>
</p>
</div>
<div class="clear"></div>
<div style="text-align:center">
<a href="javascript:hidecover('cover','loginpopup')">
Close this window
</a>
</div>
</div>
<div class="cover" id="langcover" onclick="hidecover('langcover', 'langpopup')" style="display:none">
</div>
<div class="popup" id="langpopup" style="display: none">
<div style="text-align:center">
<a href="javascript:hidecover('langcover','langpopup')">
Close this window
</a>
</div>
</div>
</div><!-- #wrapper -->
</body><div></div></html>
